{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import RandomCrop, RandomRotation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_flat_features(self, x):\n",
    "    \"\"\"return the number of flat features from a pytorch variable\"\"\"\n",
    "    return int(np.prod(x.size()[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()  # run initializer on the parent class\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        # 1 image, 6 output channels, 5x5 convolution\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward must be overwritten in torch model class\n",
    "        \"\"\"\n",
    "        # Convolutional Layers\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # add pooling layer\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        \n",
    "        x = x.view(-1, 256)  # flatten for fully connected layers\n",
    "\n",
    "        # fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"LeNet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss and optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(training=True):\n",
    "    transform_ = transforms.Compose(\n",
    "        [RandomRotation(45),\n",
    "         RandomCrop(28),\n",
    "         transforms.ToTensor()]\n",
    "    )\n",
    "    data = torchvision.datasets.MNIST(\n",
    "        root='./data/',\n",
    "        train=training,\n",
    "        download=True,\n",
    "        transform=transform_,\n",
    "    )\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        data,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "   \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data.\n",
    "If the data files do not exist, download them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = load_data(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, criterion, optimizer, verbose=False):    \n",
    "    scores = []\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "\n",
    "        # wrap features as torch Variables\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs) # forward pass\n",
    "        loss = criterion(outputs, labels)  # optimization\n",
    "        loss.backward()  # compute back propagation\n",
    "        optimizer.step()  # update model parameters\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        if i % 100 == 99:  # print every 2000 mini-batches\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).cpu().sum()\n",
    "            accuracy = 100. * correct / total\n",
    "\n",
    "            scores.append((i+1, running_loss/100, accuracy)) \n",
    "\n",
    "            # print results\n",
    "            if verbose and i % 500 == 499:\n",
    "                print('Batch: %5d - Loss: %.3f' % (i+1, running_loss/100))\n",
    "                print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
    "\n",
    "            running_loss = 0.0    \n",
    "\n",
    "    print('Finished Training')\n",
    "        \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_data(data):\n",
    "    iterations = [i[0] for i in scores]\n",
    "    loss_scores = [i[1] for i in scores]\n",
    "    acc_scores = [i[2] for i in scores]\n",
    "    \n",
    "    return iterations, loss_scores, acc_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(i, loss):\n",
    "    plt.plot(i, loss);\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.y_label('Model Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(i, acc):\n",
    "    plt.plot(i, acc);\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Step')\n",
    "    plt.y_label('Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for i in range(1):  # Our Epochs\n",
    "    print(\"Model {}...\".format(i+1))\n",
    "    net = LeNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    \n",
    "    scores = train(\n",
    "        net,  # the model\n",
    "        dataloader,  # the data provider\n",
    "        criterion,  # the loss function\n",
    "        optimizer,  # the optimization algorithm\n",
    "        verbose=False,  # print results\n",
    "    )\n",
    "    step, loss, acc = unpack_data(scores) \n",
    "    \n",
    "    net.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    results['step'] += step\n",
    "    results['loss_scores'] += loss\n",
    "    results['acc_scores'] += acc\n",
    "    results['model_n'] += [i] * len(step)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    del net, criterion, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results['step'], results['loss_scores'], alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results['step'], results['acc_scores'], alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step'] = df['step'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='step', y='acc_scores', data=df, fit_reg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
